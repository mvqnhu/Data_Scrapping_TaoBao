{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db0de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "from openpyxl import load_workbook , Workbook\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# Open chrome with current profile\n",
    "options = Options()\n",
    "\n",
    "# Path to your chrome profile\n",
    "chrome_profile_path = \"C:\\\\Users\\\\Quynh Nhu\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\\\\Profile 1\"\n",
    "options.add_argument(\"user-data-dir=\" + chrome_profile_path)\n",
    "\n",
    "# Disable automation extension\n",
    "options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "options.add_experimental_option(\"excludeSwitches\",[\"enable-automation\"])\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\") \n",
    "\n",
    "# Path to your chrome driver\n",
    "service = Service(r\"C:\\Program Files\\Google\\chromedriver-win32\\chromedriver-win32\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=service,options=options)\n",
    "\n",
    "# Now, any Chrome window opened by Selenium will use the specified profile\n",
    "driver.get(\"https://login.taobao.com/member/login.jhtml\")\n",
    "\n",
    "# Login to TaoBao\n",
    "username_input = driver.find_element(By.NAME, \"fm-login-id\")\n",
    "username_input.send_keys('id')\n",
    "password_input = driver.find_element(By.NAME, \"fm-login-password\")\n",
    "password_input.send_keys('password')\n",
    "login_button = driver.find_element(By.XPATH,\"//button[text()='登录']\") \n",
    "login_button.click()\n",
    "\n",
    "time.sleep(8)\n",
    "\n",
    "# find element of homepage\n",
    "homepage_button = driver.find_element(By.XPATH,\"//span[text()='淘宝网首页']\")\n",
    "homepage_button.click()\n",
    "\n",
    "time.sleep(8)\n",
    "\n",
    "# Find product names and links\n",
    "title = []\n",
    "prices = []  \n",
    "img_urls = []\n",
    "Sold_num = []\n",
    "Shop_name =[]\n",
    "Shop_link = []\n",
    "Link_of_product = []\n",
    "\n",
    "# List of Keywords to search:\n",
    "list_keys = [\"冬衣\",\"女式 T 恤\", \"裙子\"] # DS tên sản phẩm muốn lấy, dùng gg dịch\n",
    "\n",
    "# Num of pages every product to collect data\n",
    "num_clicks = 2  # input num_pages of product u want to get \n",
    "\n",
    "# Create loop of \"Next\" button\n",
    "def scroll_with_speed(scroll_speed):\n",
    "    current_scroll_position = 0\n",
    "    page_height = driver.execute_script(\"return Math.max(document.body.scrollHeight, document.body.offsetHeight, document.documentElement.clientHeight, document.documentElement.scrollHeight, document.documentElement.offsetHeight);\")\n",
    "    # Scroll down the bottom of page to load data\n",
    "    while current_scroll_position < page_height:\n",
    "        driver.execute_script(f\"window.scrollBy(0, {scroll_speed});\")\n",
    "        current_scroll_position += scroll_speed\n",
    "        time.sleep(0.3) \n",
    "    # Scroll up to find \"next\" button\n",
    "    driver.execute_script(\"window.scrollBy(0, -900);\")\n",
    "    \n",
    "for _ in list_keys:\n",
    "    searchbar = driver.find_element(By.CSS_SELECTOR,\"input.rax-textinput.rax-textinput-placeholder-6.searchbar-input\")\n",
    "    searchbar.send_keys(_) # input Keyword \n",
    "    search_button = driver.find_element(By.XPATH,\"//span[text()='搜索']\")\n",
    "    search_button.click() # click to find product \n",
    "    \n",
    "    # Best seller button\n",
    "    bestseller_button = driver.find_element(By.XPATH,\"//div[text()='销量']\")\n",
    "    bestseller_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Start running loop\n",
    "    for _ in range(num_clicks):\n",
    "        scroll_with_speed(50)\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Extract all elements by soup\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # Extract Title of product\n",
    "        elements = driver.find_elements(By.XPATH, \"//span[@class='']\")\n",
    "        title.extend([element.text for element in elements])\n",
    "\n",
    "        # Get image\n",
    "        products = soup.find_all('div', class_='MainPic--mainPicWrapper--iv9Yv90')\n",
    "        img_urls.extend([product.find('img')['src'] if product.find('img') else None for product in products])\n",
    "        img_urls = [value for value in img_urls if value is not None]\n",
    "\n",
    "        # Find all elements of Price with the class \n",
    "        price_elements = driver.find_elements(By.CSS_SELECTOR,'.Price--priceWrapper--Q0Dn7pN')\n",
    "        for price_element in price_elements:\n",
    "            price_unit = price_element.find_element(By.CSS_SELECTOR,'.Price--unit--VNGKLAP').text\n",
    "            price_int = price_element.find_element(By.CSS_SELECTOR,'.Price--priceInt--ZlsSi_M').text\n",
    "            price_float = price_element.find_element(By.CSS_SELECTOR,'.Price--priceFloat--h2RR0RK').text\n",
    "            realSales = price_element.find_element(By.CSS_SELECTOR,'.Price--realSales--FhTZc7U').text\n",
    "            # Construct the price and add to the list\n",
    "            price = f'{price_unit}{price_int}{price_float}'\n",
    "            prices.append(price)\n",
    "            Sold_num.append(realSales)\n",
    "\n",
    "        # Extract shop info \n",
    "        shop_elements = driver.find_elements(By.CSS_SELECTOR,'.ShopInfo--shopName--rg6mGmy')\n",
    "        Shop_name.extend([shop_element.text if shop_element.text else None for shop_element in shop_elements])\n",
    "        Shop_link.extend([shop_element.get_attribute('href') if shop_element.text else None for shop_element in shop_elements])\n",
    "\n",
    "        # Get link of product \n",
    "        product_elements = driver.find_elements(By.CSS_SELECTOR,'.Card--doubleCardWrapper--L2XFE73')\n",
    "        Link_of_product.extend([product_element.get_attribute('href') for product_element in product_elements]) \n",
    "        time.sleep(5)\n",
    "        \n",
    "        next_button = driver.find_element(By.XPATH, \"//span[text()='下一页']\")\n",
    "        next_button.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    homepage_button = driver.find_element(By.XPATH,\"//span[text()='淘宝网首页']\")\n",
    "    homepage_button.click()\n",
    "    time.sleep(2)\n",
    "        \n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d350ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Date': str(datetime.datetime.now().replace(microsecond=0)),'Title': title,'Prices': prices,'Img_urls': img_urls,'Sold_num': Sold_num,'Shop_name': Shop_name,'Shop_link': Shop_link,'Link_of_product': Link_of_product})\n",
    "# Remove the first character (currency symbol) from 'Prices' column and convert to numeric\n",
    "df['Prices'] = pd.to_numeric(df['Prices'].str.slice(1), errors='coerce')\n",
    "df['Sold_num'] = df['Sold_num'].str.split('+').str[0]\n",
    "\n",
    "# API file to ggsheet to translate then SAVE file again\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "# Authenticate with Google Sheets\n",
    "scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(r\"C:\\\\Users\\Quynh Nhu\\Downloads\\Scrapping Data\\vm-style-405901-b647d21322df.json\", scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Open the Google Sheet by title\n",
    "google_sheet_title = 'API Test_VMStyle'\n",
    "sheet = client.open(google_sheet_title).sheet1\n",
    "\n",
    "# Append the new values to the sheet\n",
    "sheet.append_rows(df.values.tolist())\n",
    "\n",
    "print(\"Data successfully added to Google Sheets.\")\n",
    "\n",
    "\n",
    "# Define the columns and corresponding formulas\n",
    "columns_formulas = [\n",
    "    ('I', '=GOOGLETRANSLATE(B:B; \"zh\"; \"vi\")'),\n",
    "    ('J', '=GOOGLETRANSLATE(E:E; \"zh\"; \"vi\")'),\n",
    "    ('K', '=ROUND(C:C*GOOGLEFINANCE(\"CURRENCY:CNYVND\"))'),\n",
    "    ('L', '=GOOGLETRANSLATE(F:F; \"zh\"; \"vi\")')]\n",
    "\n",
    "\n",
    "# Batch update formulas for each column\n",
    "for column, formula in columns_formulas:\n",
    "    column_index = ord(column) - ord('A') + 1\n",
    "    # Get all values and indices from the sheet\n",
    "    values_with_indices = [(i, value) for i, value in enumerate(sheet.col_values(1), start=1) if value != '']\n",
    "    # Extract indices from the result\n",
    "    non_empty_indices = len(values_with_indices)\n",
    "    cell_range = f'{column}2:{column}{non_empty_indices}'  # Assuming your data starts from row 2\n",
    "    # Build the batch update request\n",
    "    request = {\n",
    "        'repeatCell': {\n",
    "            'range': {'sheetId': sheet.id, 'startRowIndex': 1, 'startColumnIndex': column_index - 1,\n",
    "                      'endRowIndex': non_empty_indices , 'endColumnIndex': column_index},\n",
    "            'cell': {'userEnteredValue': {'formulaValue': formula}},\n",
    "            'fields': 'userEnteredValue.formulaValue'}\n",
    "    }\n",
    "\n",
    "    # Batch update request\n",
    "    batch_update_body = {'requests': [request]}\n",
    "    sheet.spreadsheet.batch_update(body=batch_update_body)\n",
    "\n",
    "    \n",
    "# SAVE data From ggsheet to file\n",
    "\n",
    "# Get all values from the sheet\n",
    "data = sheet.get_all_values()\n",
    "\n",
    "# Convert the data to a Pandas DataFrame\n",
    "df = pd.DataFrame(data[1:], columns=data[0])  # Assuming the first row contains column headers\n",
    "\n",
    "# Create folder to save data:\n",
    "key = list_keys    \n",
    "folder_path = \"C:\\\\Users\\\\TaoBao_Data\" \n",
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "filename = os.path.join(folder_path, f\"{now}_{key}.xlsx\")\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "excel_file_path = os.path.join(folder_path, filename)\n",
    "df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(f'Data successfully saved to {excel_file_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
